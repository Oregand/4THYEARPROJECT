# Working Main Spider

from scrapy.contrib.spiders import CrawlSpider, Rule
from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor
from scrapy.http import Request
from scrapy.contrib.loader import *
from carzone.items import CarzoneItem


class MySpider(CrawlSpider):
    name = "car2"
    allowed_domains = ["carzone.ie"]

    def start_requests(self):
        start_urls = reversed([

            "http://www.carzone.ie/search/results?nParam=4294911096%2B200590&searchsource=browse&cacheBuster=1395171710224200"
        ])
        return [Request(url=start_url) for start_url in start_urls]

    #
    # rules = (Rule(SgmlLinkExtractor(allow=('\\&page=\\d')),'parse_start_url',follow=True),)
    rules = (Rule(SgmlLinkExtractor(allow=('carzone.ie/search/*')), 'parse_start_url', follow=True),)


    def parse_start_url(self, response):
        hxs = HtmlXPathSelector(response)
        titles = hxs.select("//div[@class='vehicle-description']")
        price = hxs.select("//div[@class='vehicle-call2action']")
        deepdetails = hxs.select("//div[@class='car-details']")
        items = []

        for titles in titles:
            item = CarzoneItem()
            item["title"] = titles.select("div[@class='vehicle-make-model']/h3/a/text()").extract()
            item["link"] = titles.select("div[@class='vehicle-make-model']/h3/a/@href").extract()
            item["carYear"] = titles.select("*[@class='vehicle-year']/text()").extract()[0].strip()
            item["location"] = \
                titles.select("div[@class='vehicle-props']/div[@class='vehicle-location']/span/text()").extract()[
                    0].strip()
            item["price"] = price.select("div[@class='vehicle-price']/text()").extract()[0].strip()

            """ There seems to be some issue with the format of these two items, need to slowly eliminate spaces within scraped data"""
            item["mileage"] = titles.select("div[@class='vehicle-mileage']/text()").extract()[0].strip()
            item["engine"] = titles.select("div[@class='vehicle-engine last-sep']/text()").extract()[0].strip()

            """ Deep layer details """
            item["Transmission"] = deepdetails.select("div[@class='advertDetailsTransmission']/text()").extract()[
                0].strip()

            items.append(item)
        return items




        #item ["job_id"] = map(unicode.strip, id.select('text()').extract())


#DB Log in





#Second Spider

from scrapy.contrib.spiders import CrawlSpider, Rule
from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor
from scrapy.selector import HtmlXPathSelector
from carzone.items import CarzoneItem


class MySpider(CrawlSpider):
    name = "second"
    allowed_domains = ["www.carzone.ie"]
    start_url = ["http://www.carzone.ie/search/results?nParam=4294911140%2B200590&searchsource=browse&cacheBuster=1392117041518767"]

    def parse_items_1(self, response):
        items = []
        hxs = HtmlXPathSelector(response)
        titles = hxs.select("//div")
        for title in titles:
            item = CarzoneItem()
            item ["title"] = title.select("//li/a/text()").extract()
            item ["link"] = title.select("//li/a/@href").extract()
            print ('**parse-items_1:', item["title"])
            items.append(item)
        return items

    def parse_items_2(self, response):
        hxs = HtmlXPathSelector(response)
        titles = hxs.select("//p")
        items = []
        for title in titles:
            item = CarzoneItem()
            item ["title"] = title.select("a/text()").extract()
            item ["link"] = title.select("a/@href").extract()
            print ('**parse_items_2:', item["title"], item["link"])
            items.append(item)
        return items